{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.0-modeling-clustering-classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkapitan/jads-nhs-proms/blob/master/notebooks/4.0-modeling-clustering-classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QeHjN1GFNwqC"
      },
      "source": [
        "# Background to osteoarthritis case study\n",
        "\n",
        "_taken from [narrative seminar Osteoarthritis by Hunter & Bierma-Zeinstra (2019) in the Lancet](https://github.com/dkapitan/jads-nhs-proms/blob/master/references/hunter2019osteaoarthritis.pdf)._\n",
        "\n",
        "Outcomes from total joint replacement can be optimised if patient selection identifies marked joint space narrowing. Most improvement will be made in patients with complete joint space loss and evident bone attrition. Up to 25% of patients presenting for total joint replacement continue to complain of pain and disability 1 year after well performed surgery. Careful preoperative patient selection (including consideration of the poor outcomes that are more common in people who are depressed, have minimal radiographic disease, have minimal pain, and who are morbidly obese), shared decision making about surgery, and informing patients about realistic outcomes of surgery are needed to minimise the likelihood of dissatisfaction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ps-NB5SwlrNd"
      },
      "source": [
        "# Modeling: clustering & classfication\n",
        "\n",
        "This is day 4 from the [5-day JADS NHS PROMs data science case study](https://github.com/dkapitan/jads-nhs-proms/blob/master/references/outline.md).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C1bEDtlnF4a9"
      },
      "source": [
        "\n",
        "## Learning objectives: modeling\n",
        "- ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "osBitZ5yF7lM"
      },
      "source": [
        "## Learning objectives Python: Hands-on Machine Learning (2nd edition)\n",
        "\n",
        "- [End-to-end Machine Learning project (chapter 2)](https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb)\n",
        "- [Unsupervised learning (chapter 9)](https://github.com/ageron/handson-ml2/blob/master/09_unsupervised_learning.ipynb)\n",
        "- [Classification (chapter 3](https://github.com/ageron/handson-ml2/blob/master/03_classification.ipynb)\n",
        "- [Support-vector machines (chapter 5](https://github.com/ageron/handson-ml2/blob/master/05_support_vector_machines.ipynb)\n",
        "- [Decision trees (chapter 6)](https://github.com/ageron/handson-ml2/blob/master/06_decision_trees.ipynb)\n",
        "- [Ensemble learning and random forests (chapter 7](https://github.com/ageron/handson-ml2/blob/master/07_ensemble_learning_and_random_forests.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "npvciVNWF_0U"
      },
      "source": [
        "## Recap from previous lecture\n",
        "- Good outcome for knee replacement Y is measured using difference in Oxford Knee Score (OKS)\n",
        "- Research has shown that an improvement in OKS score of approx. 30% is relevant ([van der Wees 2017](https://github.com/dkapitan/jads-nhs-proms/blob/master/references/vanderwees2017patient-reported.pdf)). Hence an increase of +14 points is considered a 'good' outcome.\n",
        "- to account for the ceiling effect, a high final `t1_oks_score` is also considered as a good outcome (even if `delta_oks_score` is smaller than 14).\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_95_D3ywlrNh",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import chi2, VarianceThreshold\n",
        "import sklearn.linear_model\n",
        "\n",
        "#supressing warnings for readability\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# To plot pretty figures directly within Jupyter\n",
        "%matplotlib inline\n",
        "\n",
        "# choose your own style: https://matplotlib.org/3.1.0/gallery/style_sheets/style_sheets_reference.html\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Go to town with https://matplotlib.org/tutorials/introductory/customizing.html\n",
        "# plt.rcParams.keys()\n",
        "mpl.rc('axes', labelsize=14, titlesize=14)\n",
        "mpl.rc('figure', titlesize=20)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# contants for figsize\n",
        "S = (8,8)\n",
        "M = (12,12)\n",
        "L = (14,14)\n",
        "\n",
        "# pandas options\n",
        "pd.set_option(\"display.max.columns\", None)\n",
        "pd.set_option(\"display.max.rows\", None)\n",
        "pd.set_option(\"display.precision\", 2)\n",
        "\n",
        "# import data\n",
        "df = pd.read_parquet('https://github.com/dkapitan/jads-nhs-proms/blob/master/data/interim/knee-provider.parquet?raw=true')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dJDC2qMzPDf6"
      },
      "source": [
        "# Data preparation in a scikit-learn Pipeline\n",
        "Previously we have already discussed the various steps in data preparation using [pandas](https://pandas.pydata.org/). As explained in the [documentation of scikit-learn](https://scikit-learn.org/stable/modules/compose.html#column-transformer), this may be problematic for one of the following reasons:\n",
        "\n",
        "* Incorporating statistics from test data into the preprocessors makes cross-validation scores unreliable (known as data leakage), for example in the case of scalers or imputing missing values.\n",
        "\n",
        "* You may want to include the parameters of the preprocessors in a [parameter search](https://scikit-learn.org/stable/modules/grid_search.html#grid-search).\n",
        "\n",
        "To this purpose, the [`ColumnTransformer` class](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html?highlight=columntransformer#sklearn.compose.ColumnTransformer) has been recently added to scikit-learn. The documentation gives an example how to use this for [pre-processing mixed types](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py). Historically, `sklearn` transformers are designed to work with numpy arrays, not with pandas dataframes. You can use [`sklearn-pandas`](https://github.com/scikit-learn-contrib/sklearn-pandas) to bridge this gap or use `ColumnTransformer` directly on pandas DataFrames. We will use the latter.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIcSarjLf_-T",
        "colab_type": "text"
      },
      "source": [
        "## Writing custom transformers (advanced, see GÃ©ron chapter 2)\n",
        "Although Scikit-Learn provides many useful transformers, you will need to write your own for tasks such as custom cleanup operations or combining specific attributes. You will want your transformer to work seamlessly with Scikit-Learn functionalities (such as pipelines), and since Scikit-Learn relies on duck typing (not inheritance), all you need to do is create a class and implement three methods: fit() (returning self), transform(), and fit_transform().\n",
        "\n",
        "When writing transformers for data preparation, you only need to define `transform()`. Basically, `ColumnTransformer` passes only the subset of columns from the original dataframe to the transformer. So when writing your own transformer you don't need to do any subsetting, but you can assume that the `transform()` method should be applied to the whole dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pClpNAvogR0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "impute_median = SimpleImputer(strategy='median')\n",
        "impute_most_frequent = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "class ReplaceSentinels(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Replace sentinel values in dataframe.\n",
        "    \n",
        "    Attributes:\n",
        "        sentinel: sentinel value, default 9\n",
        "        replace_with: value to replace sentinel with, default np.nan\n",
        "    \"\"\"\n",
        "    def __init__(self, sentinel = 9, replace_with=np.nan):\n",
        "        self.sentinel = sentinel\n",
        "        self.replace_with = replace_with\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, ):\n",
        "        return X.replace(9, self.replace_with)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v09MkwoEaiX9"
      },
      "source": [
        "## Using ColumnTransformer and Pipline\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sTqApjEpKElS",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "# group columns\n",
        "comorb = ['heart_disease', 'high_bp', 'stroke', 'circulation', 'lung_disease', 'diabetes',\n",
        "           'kidney_disease', 'nervous_system', 'liver_disease', 'cancer', 'depression', 'arthritis']\n",
        "boolean = ['t0_assisted', 't0_previous_surgery', 't0_disability']\n",
        "eq5d = ['t0_mobility', 't0_self_care', 't0_activity', 't0_discomfort', 't0_anxiety']\n",
        "eq_vas = ['t0_eq_vas', 't1_eq_vas']\n",
        "categorical = ['t0_symptom_period', 't0_previous_surgery', 't0_living_arrangements']\n",
        "useless = ['t0_assisted_by', 't0_eq5d_index', 't0_eq5d_index_profile']\n",
        "\n",
        "# list of columns which contain 9s as sentinel values\n",
        "cols_with_9 = [col for col in df.columns \n",
        "               if ((df[col]==9).any() and \n",
        "                   col not in [comorb + [ 't0_eq_vas', 't1_eq_vas','oks_t0_score', 'oks_t1_score']])\n",
        "                   ]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLp2OHFaEvCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comorb_tf = ColumnTransformer([('sentinels',\n",
        "                                ReplaceSentinels(sentinel=9, replace_with=0),\n",
        "                                comorb)])\n",
        "_ = comorb_tf.fit(df[comorb])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCVQm5KucWc5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f91131eb-a26b-49e8-ada2-ce2d12306673"
      },
      "source": [
        "_.transform(df[comorb])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 1, 0, ..., 0, 0, 1]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxHvElEKEuHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# ColumnTransformer replace 9 with np.nan and impute most frequent\n",
        "ct = ColumnTransformer(\n",
        "    [('replace9', replace_9(), cols_with_9),\n",
        "     ('impute_most_frequent', )],\n",
        "            \n",
        "\n",
        "\n",
        "# \n",
        "dfc.loc[:,cols_sentinel_9] = \n",
        "impute_most_frequent.fit(dfc[cols_sentinel_9]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P98AGZqgViAX",
        "outputId": "6adfd50a-7b4c-442e-c209-3072ce71be7c",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# use copy of original data\n",
        "dfc = df.copy()\n",
        "\n",
        "\n",
        "\n",
        "# assign imputed data\n",
        "dfc.loc[:, cols_sentinel_9] = impute_most_frequent.transform(dfc[cols_sentinel_9])\n",
        "\n",
        "# same procedure for 999 sentinel values, using impute median\n",
        "\n",
        "dfc.loc[:, eq_vas] = dfc.loc[:,eq_vas].replace(999, np.nan)\n",
        "impute_median.fit(dfc.loc[:,eq_vas])\n",
        "dfc.loc[:,eq_vas] = impute_median.transform(dfc.loc[:,eq_vas])\n",
        "impute_median.statistics_\n",
        "\n",
        "# transform into boolean\n",
        "dfc['female'] = dfc.loc[:,'gender'].replace({1: False, 2: True})\n",
        "dfc.loc[:, comorb] = dfc.loc[:, comorb].replace({9: False, 1: True})\n",
        "dfc.loc[:, boolean] = dfc.loc[:, boolean].replace({1: True, 2: False})\n",
        "\n",
        "# helper function for counting boolean attribues\n",
        "def count_boolean(series):\n",
        "    '''\n",
        "    Returns absolute and normalized value counts of pd.series as a dataframe with \n",
        "    index = series.name\n",
        "    columns with absolute and normalized counts of each value\n",
        "    '''\n",
        "    try:\n",
        "        count = series.value_counts().to_frame().transpose()\n",
        "        norm = series.value_counts(normalize=True).to_frame().transpose()\n",
        "        return count.join(norm, lsuffix='_count', rsuffix='_normalized') \n",
        "    except:\n",
        "        print('Error: expecting a pandas.Series object as input. \\n' + count_boolean.__doc__)\n",
        "        return None\n",
        "\n",
        "pd.concat([count_boolean(dfc[col]) for col in ['female'] + comorb + boolean]).round(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cols_sentinel_9' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-115b82553376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# replace 9 with np.nan and impute most frequent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols_sentinel_9\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols_sentinel_9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mimpute_most_frequent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_sentinel_9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cols_sentinel_9' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uwZprioyQd0s"
      },
      "source": [
        "## Inspect categorical features (T0)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2s0BJW7zcmtJ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3s3U5oq00ton",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EwECD0NUlc3Z",
        "colab": {}
      },
      "source": [
        "# convert to categories\n",
        "dfc.loc[:, ['provider_code', 'age_band']] = dfc.loc[:, ['provider_code', 'age_band']].astype('category')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hk2ih7gEjMMW"
      },
      "source": [
        "## Discussion\n",
        "\n",
        "### **Question:** ...\n",
        "- ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KHnA3F9nocH2"
      },
      "source": [
        "# Selecting data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "US0VziEQqUxT"
      },
      "source": [
        "## Selecting input features X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i2xVdjCQojQH",
        "colab": {}
      },
      "source": [
        "# input features\n",
        "# TO DO: decide what to do with years?!\n",
        "\n",
        "# feature engineering\n",
        "dfc['oks_t0_pain_total'] = dfc['oks_t0_pain'] + dfc['oks_t0_night_pain']\n",
        "dfc['n_comorb'] = dfc.loc[:,comorb].sum()\n",
        "\n",
        "X_features = ['provider_code', 'female', 'age_band'] + comorb + boolean + eq5d_questions('t0') + oks_questions('t0') + ['t0_eq_vas', 'oks_t0_pain_total', 'n_comorb']\n",
        "X_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "poHEugvVqrNz"
      },
      "source": [
        "## Selecting outcome Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "81Nz5x2oo3-N",
        "colab": {}
      },
      "source": [
        "# add delta_oks_score and Y\n",
        "def good_outcome(oks_t1, delta_oks, abs_threshold=43, mcid=13):\n",
        "  if oks_t1 > abs_threshold or delta_oks > mcid:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "dfc['delta_oks_score'] = dfc.oks_t1_score - dfc.oks_t0_score\n",
        "dfc['Y'] = dfc.apply(lambda row: good_outcome(row['oks_t1_score'], row['delta_oks_score']), axis=1)\n",
        "dfc.Y.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kw3m1k3EI6NK"
      },
      "source": [
        "# Getting into scikit-learn: regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EZMdkbZyJoru"
      },
      "source": [
        "## Simple linear regression\n",
        "To illustrate linear regression, we use `t1_eq_vas` as numeric outcome. First we will assess whether there is a correlation between `t0` and `t1` values of `eq_vas`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w-4srrk5JErU",
        "colab": {}
      },
      "source": [
        "dfc.plot(kind='scatter', x='t0_eq_vas', y='t1_eq_vas', figsize=M, alpha=0.2);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mdGCMu92KiGe",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# x needs to be a column vector or an matrix\n",
        "x = dfc.t0_eq_vas.values.reshape(-1, 1)\n",
        "\n",
        "# y is a row vector\n",
        "y = dfc.t1_eq_vas.values\n",
        "print(f'x: {x[:5]}\\n y: {y[:5]}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wNlk_HMYM6Gr",
        "colab": {}
      },
      "source": [
        "# linear regression with t0_eq_vas\n",
        "lr = LinearRegression().fit(x, y)\n",
        "r2 = lr.score(x, y)\n",
        "print(f'r2: {r2:.2f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IoHiFX8pPpt9"
      },
      "source": [
        "## Regression with decision trees\n",
        "Next, let's try more parameters to perform regression on `t1_eq_vas`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a6dtjlOoP28r",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# regression can only take numeric input features\n",
        "X = dfc.loc[:, X_features].select_dtypes(include='float64').drop(columns=['n_comorb'])\n",
        "y = dfc.t1_eq_vas.values\n",
        "dtr = DecisionTreeRegressor().fit(X,y)\n",
        "dt_r2 = dtr.score(X, y)\n",
        "print(f'DecisionTreeRegressor r2: {dt_r2:.2f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2zm3Ru8CX6Td",
        "colab": {}
      },
      "source": [
        "# this doesn't make sense, probably overfitting\n",
        "dtr = DecisionTreeRegressor(max_depth=5).fit(X,y)\n",
        "dt_r2 = dtr.score(X, y)\n",
        "print(f'DecisionTreeRegressor r2: {dt_r2:.2f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UXRVdLXMUrCy"
      },
      "source": [
        "# Conclusion and reflection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uhtn2ycxX-KV"
      },
      "source": [
        "## Discussion of results\n",
        "\n",
        "* ...\n",
        "* ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EyYH6A2yUwy3"
      },
      "source": [
        "## Checklist for results from data preparation process\n",
        "* Input regarding the moment of prediction\n",
        "* Input for data cleaning (handling missing data; removing variables not known at time of prediction, near-zero variance variables, etc)\n",
        "* Input for feature engineering (adjusting variables based on tree-analyses, based on correlations, based on domain-analysis)\n",
        "* Input for defining the outcome variable Y\n",
        "* Input for defining the business objective in terms of generalizability (in case of missing Y values)\n",
        "* Input for choosing the business objective in case there are still multiple options at the table\n",
        "* Input for defining the scope of the business objective (e.g. limiting to a subgroup to get a better balanced outcome variable)\n",
        "* A potential revision of the goal of your business objective\n",
        "* Input for which variables and combination of variables seem particularly relevant within the to-be-developed algorithms "
      ]
    }
  ]
}