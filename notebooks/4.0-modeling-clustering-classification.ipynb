{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkapitan/jads-nhs-proms/blob/master/notebooks/4.0-modeling-clustering-classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QeHjN1GFNwqC"
      },
      "source": [
        "# Background to osteoarthritis case study\n",
        "\n",
        "_taken from [narrative seminar Osteoarthritis by Hunter & Bierma-Zeinstra (2019) in the Lancet](https://github.com/dkapitan/jads-nhs-proms/blob/master/references/hunter2019osteaoarthritis.pdf)._\n",
        "\n",
        "Outcomes from total joint replacement can be optimised if patient selection identifies marked joint space narrowing. Most improvement will be made in patients with complete joint space loss and evident bone attrition. Up to 25% of patients presenting for total joint replacement continue to complain of pain and disability 1 year after well performed surgery. Careful preoperative patient selection (including consideration of the poor outcomes that are more common in people who are depressed, have minimal radiographic disease, have minimal pain, and who are morbidly obese), shared decision making about surgery, and informing patients about realistic outcomes of surgery are needed to minimise the likelihood of dissatisfaction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ps-NB5SwlrNd"
      },
      "source": [
        "# Modeling: clustering & classfication\n",
        "\n",
        "This is day 4 from the [5-day JADS NHS PROMs data science case study](https://github.com/dkapitan/jads-nhs-proms/blob/master/references/outline.md).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C1bEDtlnF4a9"
      },
      "source": [
        "\n",
        "## Learning objectives: modeling\n",
        "- ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "osBitZ5yF7lM"
      },
      "source": [
        "## Learning objectives Python: Hands-on Machine Learning (2nd edition)\n",
        "\n",
        "- [End-to-end Machine Learning project (chapter 2)](https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb)\n",
        "- [Unsupervised learning (chapter 9)](https://github.com/ageron/handson-ml2/blob/master/09_unsupervised_learning.ipynb)\n",
        "- [Classification (chapter 3](https://github.com/ageron/handson-ml2/blob/master/03_classification.ipynb)\n",
        "- [Support-vector machines (chapter 5](https://github.com/ageron/handson-ml2/blob/master/05_support_vector_machines.ipynb)\n",
        "- [Decision trees (chapter 6)](https://github.com/ageron/handson-ml2/blob/master/06_decision_trees.ipynb)\n",
        "- [Ensemble learning and random forests (chapter 7](https://github.com/ageron/handson-ml2/blob/master/07_ensemble_learning_and_random_forests.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "npvciVNWF_0U"
      },
      "source": [
        "## Recap from previous lecture\n",
        "- Good outcome for knee replacement Y is measured using difference in Oxford Knee Score (OKS)\n",
        "- Research has shown that an improvement in OKS score of approx. 30% is relevant ([van der Wees 2017](https://github.com/dkapitan/jads-nhs-proms/blob/master/references/vanderwees2017patient-reported.pdf)). Hence an increase of +14 points is considered a 'good' outcome.\n",
        "- to account for the ceiling effect, a high final `t1_oks_score` is also considered as a good outcome (even if `delta_oks_score` is smaller than 14).\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_95_D3ywlrNh",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import chi2, VarianceThreshold\n",
        "import sklearn.linear_model\n",
        "\n",
        "#supressing warnings for readability\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# To plot pretty figures directly within Jupyter\n",
        "%matplotlib inline\n",
        "\n",
        "# choose your own style: https://matplotlib.org/3.1.0/gallery/style_sheets/style_sheets_reference.html\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Go to town with https://matplotlib.org/tutorials/introductory/customizing.html\n",
        "# plt.rcParams.keys()\n",
        "mpl.rc('axes', labelsize=14, titlesize=14)\n",
        "mpl.rc('figure', titlesize=20)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# contants for figsize\n",
        "S = (8,8)\n",
        "M = (12,12)\n",
        "L = (14,14)\n",
        "\n",
        "# pandas options\n",
        "pd.set_option(\"display.max.columns\", None)\n",
        "pd.set_option(\"display.max.rows\", None)\n",
        "pd.set_option(\"display.precision\", 2)\n",
        "\n",
        "# import data\n",
        "df = pd.read_parquet('https://github.com/dkapitan/jads-nhs-proms/blob/master/data/interim/knee-provider.parquet?raw=true')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dJDC2qMzPDf6"
      },
      "source": [
        "# Data preparation in a scikit-learn Pipeline\n",
        "Previously we have already discussed the various steps in data preparation using [pandas](https://pandas.pydata.org/). As explained in the [documentation of scikit-learn](https://scikit-learn.org/stable/modules/compose.html#column-transformer), this may be problematic for one of the following reasons:\n",
        "\n",
        "* Incorporating statistics from test data into the preprocessors makes cross-validation scores unreliable (known as data leakage), for example in the case of scalers or imputing missing values.\n",
        "\n",
        "* You may want to include the parameters of the preprocessors in a [parameter search](https://scikit-learn.org/stable/modules/grid_search.html#grid-search).\n",
        "\n",
        "To this purpose, the [`ColumnTransformer` class](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html?highlight=columntransformer#sklearn.compose.ColumnTransformer) has been recently added to scikit-learn. The documentation gives an example how to use this for [pre-processing mixed types](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py). Historically, `sklearn` transformers are designed to work with numpy arrays, not with pandas dataframes. You can use [`sklearn-pandas`](https://github.com/scikit-learn-contrib/sklearn-pandas) to bridge this gap or use `ColumnTransformer` directly on pandas DataFrames. We will use the latter.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvToMd6emVyn",
        "colab_type": "text"
      },
      "source": [
        "## Using ColumnsTransformers and Pipelines\n",
        "\n",
        "Recalling from the second lecture, we want to perform the following preprocessing per (group of) columns. In case feature requires more than one preprocessing step, the use of `Pipeline` is recommended.\n",
        "\n",
        "### Passing 1D or 2D arrays in your `Pipeline`\n",
        "It is important to remember that `scikit-learn` can be quite fussy about the difference between passing 1D arrays/series and 2D arrays/dataframes.\n",
        "\n",
        "For example, the following code will result in an error because `categories` needs to be a list of lists:\n",
        "```\n",
        "enc = OrdinalEncoder(categories=age_band_categories)\n",
        "enc.fit(df[age_band])\n",
        "```\n",
        "\n",
        "The correct code is (brackets!):\n",
        "```\n",
        "enc = OrdinalEncoder(categories=[age_band_categories])\n",
        "enc.fit(df[age_band])\n",
        "```\n",
        "\n",
        "\n",
        "### Beware: difference between `OrdinalEncoder` and `OneHotEncoding`\n",
        "Using `OrdinalEncoder` to generate an integer representation of a categorical variable can not be used directly with all scikit-learn estimators, as these expect continuous input, and would interpret the categories as being ordered, which is often not desired.\n",
        "\n",
        "Another possibility to convert categorical features to features that can be used with scikit-learn estimators is to use a one-of-K, also known as one-hot or dummy encoding. This type of encoding can be obtained with the OneHotEncoder, which transforms each categorical feature with n_categories possible values into n_categories binary features, with one of them 1, and all others 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pClpNAvogR0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "a75dd985-78c3-42be-dd93-7fc204690e6a"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "# group columns\n",
        "age_band = ['age_band']\n",
        "gender = ['gender']\n",
        "age_band_categories = sorted([x for x in df.age_band.unique() if x])\n",
        "comorb = ['heart_disease', 'high_bp', 'stroke', 'circulation', 'lung_disease',\n",
        "          'diabetes', 'kidney_disease', 'nervous_system', 'liver_disease',\n",
        "          'cancer', 'depression', 'arthritis']\n",
        "boolean = ['t0_assisted', 't0_previous_surgery', 't0_disability']\n",
        "eq5d = ['t0_mobility', 't0_self_care', 't0_activity', 't0_discomfort',\n",
        "        't0_anxiety']\n",
        "eq_vas = ['t0_eq_vas']\n",
        "categorical = ['t0_symptom_period', 't0_previous_surgery',\n",
        "               't0_living_arrangements']\n",
        "oks_questions = [col for col in df.columns \n",
        "                 if col.startswith('oks_t0')\n",
        "                 and not col.endswith('_score')]\n",
        "oks_score = ['oks_t0_score']\n",
        "\n",
        "# preprocessing pipelines for specific columns\n",
        "age_band_pipe = Pipeline(\n",
        "    steps=[('impute',\n",
        "            SimpleImputer(missing_values=None,\n",
        "            strategy='most_frequent')),\n",
        "           ('ordinal',\n",
        "            OrdinalEncoder(categories=[age_band_categories])),\n",
        "           ])\n",
        "\n",
        "gender_pipe = Pipeline(\n",
        "    steps=[('impute',\n",
        "           SimpleImputer(missing_values=np.nan,\n",
        "                         strategy='most_frequent')),\n",
        "           ('onehot', OneHotEncoder()),\n",
        "           ])\n",
        "\n",
        "\n",
        "# ColumnTransformer on all included columns.\n",
        "# Note columns that are not specified are dropped by default\n",
        "prep = ColumnTransformer(\n",
        "    transformers=[('age',\n",
        "                   age_band_pipe,\n",
        "                   ['age_band']),\n",
        "                  ('gender',\n",
        "                   gender_pipe,\n",
        "                   gender),\n",
        "                  ('constant',\n",
        "                   SimpleImputer(missing_values=9,\n",
        "                                 strategy='constant',\n",
        "                                 fill_value=0),\n",
        "                   comorb),\n",
        "                  ('most_frequent',\n",
        "                   SimpleImputer(missing_values=9,\n",
        "                                 strategy='most_frequent'),\n",
        "                   boolean + eq5d + categorical),\n",
        "                  ('eqvas',\n",
        "                   SimpleImputer(missing_values=999,\n",
        "                                 strategy='median'),\n",
        "                   eq_vas),\n",
        "                  ('oks',\n",
        "                   SimpleImputer(missing_values=9,\n",
        "                                 strategy='most_frequent'),\n",
        "                   oks_questions),\n",
        "                  ('oks_score',\n",
        "                   SimpleImputer(missing_values=np.nan,\n",
        "                                 strategy='most_frequent'),\n",
        "                   oks_score),\n",
        "                  ])\n",
        "\n",
        "prep.fit(df)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
              "                  transformer_weights=None,\n",
              "                  transformers=[('age',\n",
              "                                 Pipeline(memory=None,\n",
              "                                          steps=[('impute',\n",
              "                                                  SimpleImputer(add_indicator=False,\n",
              "                                                                copy=True,\n",
              "                                                                fill_value=None,\n",
              "                                                                missing_values=None,\n",
              "                                                                strategy='most_frequent',\n",
              "                                                                verbose=0)),\n",
              "                                                 ('ordinal',\n",
              "                                                  OrdinalEncoder(categories=[['40 '\n",
              "                                                                              'to '\n",
              "                                                                              '49',\n",
              "                                                                              '50 '\n",
              "                                                                              'to '\n",
              "                                                                              '59',\n",
              "                                                                              '60 '\n",
              "                                                                              'to '\n",
              "                                                                              '69',\n",
              "                                                                              '70...\n",
              "                                 ['oks_t0_pain', 'oks_t0_night_pain',\n",
              "                                  'oks_t0_washing', 'oks_t0_transport',\n",
              "                                  'oks_t0_walking', 'oks_t0_standing',\n",
              "                                  'oks_t0_limping', 'oks_t0_kneeling',\n",
              "                                  'oks_t0_work', 'oks_t0_confidence',\n",
              "                                  'oks_t0_shopping', 'oks_t0_stairs']),\n",
              "                                ('oks_score',\n",
              "                                 SimpleImputer(add_indicator=False, copy=True,\n",
              "                                               fill_value=None,\n",
              "                                               missing_values=nan,\n",
              "                                               strategy='most_frequent',\n",
              "                                               verbose=0),\n",
              "                                 ['oks_t0_score'])],\n",
              "                  verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIcSarjLf_-T",
        "colab_type": "text"
      },
      "source": [
        "## Writing custom transformers (advanced, see GÃ©ron chapter 2)\n",
        "Although Scikit-Learn provides many useful transformers, you will need to write your own for tasks such as custom cleanup operations or combining specific attributes. You will want your transformer to work seamlessly with Scikit-Learn functionalities (such as pipelines), and since Scikit-Learn relies on duck typing (not inheritance), all you need to do is create a class and implement three methods: fit() (returning self), transform(), and fit_transform().\n",
        "\n",
        "When writing transformers for data preparation, you only need to define `transform()`. Basically, `ColumnTransformer` passes only the subset of columns from the original dataframe to the transformer. So when writing your own transformer you don't need to do any subsetting, but you can assume that the `transform()` method should be applied to the whole dataframe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sTqApjEpKElS",
        "colab": {}
      },
      "source": [
        "# just as an example, not used in Pipeline\n",
        "class ReplaceSentinels(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Replace sentinel values in dataframe.\n",
        "    \n",
        "    Attributes:\n",
        "        sentinel: sentinel value, default 9\n",
        "        replace_with: value to replace sentinel with, default np.nan\n",
        "    \"\"\"\n",
        "    def __init__(self, sentinel = 9, replace_with=np.nan):\n",
        "        self.sentinel = sentinel\n",
        "        self.replace_with = replace_with\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, ):\n",
        "        return X.replace(9, self.replace_with)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v09MkwoEaiX9"
      },
      "source": [
        "## Preproces Y and train-test split\n",
        "After preprocessing X, we now need to preprocess Y and perform train-test split.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EwECD0NUlc3Z",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def fill_median(s):\n",
        "    return s.fillna(value=s.median()) \n",
        "\n",
        "def good_outcome(oks_t1, delta_oks, abs_threshold=43, mcid=13):\n",
        "  if oks_t1 > abs_threshold or delta_oks > mcid:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "t1 = [col for col in df.columns if col.startswith(('oks_t1', 't1'))]\n",
        "Y = df[t1].copy()\n",
        "Y['t1_oks_score'] = fill_median(df.oks_t1_score)\n",
        "Y['t1_delta_oks_score'] =  Y.t1_oks_score - fill_median(df.oks_t0_score)\n",
        "Y['y'] = Y.apply(lambda row: good_outcome(row['oks_t1_score'], row['t1_delta_oks_score']), axis=1)\n",
        "\n",
        "features = age_band + gender + comorb + boolean + eq5d + categorical + eq_vas + oks_questions + oks_score\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[features], Y.y, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kw3m1k3EI6NK"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Single estimators: Stochastic Gradient Descent, Decision tree, LinearSVC,  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "sgd = Pipeline(steps=[('prep', prep),\n",
        "'clf', SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)])\n",
        "cart = Pipeline(steps=[('prep', prep),\n",
        "                          ('clf', DecisionTreeClassifier(max_depth=5, random_state=42))])\n",
        "svm = Pipeline(steps=[('prep', prep),\n",
        "                          ('clf', LinearSVC(random_state=42))])\n",
        "\n",
        "# https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py\n",
        "# use regular GridSearchCV with single models\n",
        "sgd_parameters = {\n",
        "'clf__loss': ['hinge'],\n",
        "'clf__penalty': ['l2'],\n",
        "'clf__max_iter': [2, 5, 10]\n",
        "}\n",
        "\n",
        "sgd_grid_search = GridSearchCV(sgd, sgd_parameters, cv=5)\n",
        "\n",
        "\n",
        "for pipeline in [sgd, cart, svm]:\n",
        "    print(f\"{pipeline.named_steps['clf']}: ...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EZMdkbZyJoru"
      },
      "source": [
        "## Ensemble methods: Random Forest & GradientBoosted Trees\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w-4srrk5JErU",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "\n",
        "rf_clf = Pipeline(steps=[('prep', prep),\n",
        "                          ('rf', RandomForestClassifier(n_estimators=100,\n",
        "                                                        random_state=42))])\n",
        "gb_clf = Pipeline(steps=[('prep', prep),\n",
        "                          ('gb', GradientBoostingClassifier(n_estimators=100, learning_rate=1.0))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0Hlv--UvLii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95e2d292-218d-4c04-9c39-e8b1d188abfc"
      },
      "source": [
        "rf_clf.fit(X_train, y_train)\n",
        "print(f'Random Forest model score: {rf_clf.score(X_test, y_test):.2f}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest model score: 0.70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9tFEDaQwa5p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "245e256d-6af1-41e2-93db-be9aee00c1f8"
      },
      "source": [
        "svm_clf.fit(X_train, y_train)\n",
        "print(f'SVM model score: {svm_clf.score(X_test, y_test):.2f}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM model score: 0.36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UXRVdLXMUrCy"
      },
      "source": [
        "# Conclusion and reflection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uhtn2ycxX-KV"
      },
      "source": [
        "## Discussion of results\n",
        "\n",
        "* ...\n",
        "* ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EyYH6A2yUwy3"
      },
      "source": [
        "## Checklist for results from data preparation process\n",
        "* ...\n",
        "* ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZWO42C6uTb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "4.0-modeling-clustering-classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}